# Default Open AI Scala Client Config

openai-scala-client {
    apiKey = ${?OPENAI_SCALA_CLIENT_API_KEY}
    orgId = ${?OPENAI_SCALA_CLIENT_ORG_ID}

    timeouts {
        requestTimeoutSec = 200
        readTimeoutSec = 200
#        connectTimeoutSec = 5
#        pooledConnectionIdleTimeoutSec = 60
    }

    # Models that support JSON schema structured output
    models-supporting-json-schema = [
        # GPT-5.2
        "gpt-5.2",
        "gpt-5.2-2025-12-11",
        "gpt-5.2-pro",
        "gpt-5.2-pro-2025-12-11",
        # GPT-5.1
        "gpt-5.1",
        "gpt-5.1-2025-11-13",
        # GPT-5
        "gpt-5",
        "gpt-5-pro",
        "gpt-5-pro-2025-10-06",
        "gpt-5-2025-08-07",
        "gpt-5-mini",
        "gpt-5-mini-2025-08-07",
        "gpt-5-nano",
        "gpt-5-nano-2025-08-07",
        "gpt-5-chat-latest",
        # GPT-4.1
        "gpt-4.1",
        "gpt-4.1-2025-04-14",
        "gpt-4.1-mini",
        "gpt-4.1-mini-2025-04-14",
        "gpt-4.1-nano",
        "gpt-4.1-nano-2025-04-14",
        # GPT-4.5
        "gpt-4.5-preview",
        "gpt-4.5-preview-2025-02-27",
        # GPT-4o
        "gpt-4o",
        "gpt-4o-2024-08-06",
        "gpt-4o-2024-11-20",
        # O models
        "o4-mini",
        "o4-mini-2025-04-16",
        "o3-pro",
        "o3-pro-2025-06-10",
        "o3",
        "o3-2025-04-16",
        "o3-mini",
        "o3-mini-high",
        "o3-mini-2025-01-31",
        "o1",
        "o1-2024-12-17",
        "o1-pro",
        "o1-pro-2025-03-19",
        # Claude (Anthropic)
        "claude-opus-4-5",
        "claude-opus-4-5-20251101",
        "claude-opus-4-1",
        "claude-opus-4-1-20250805",
        "claude-sonnet-4-5",
        "claude-sonnet-4-5-20250929",
        "claude-haiku-4-5",
        "claude-haiku-4-5-20251001",
        "claude-opus-4-5_thinking",
        "claude-opus-4-5-20251101_thinking",
        "claude-opus-4-1_thinking",
        "claude-opus-4-1-20250805_thinking",
        "claude-sonnet-4-5_thinking",
        "claude-sonnet-4-5-20250929_thinking",
        # OpenAI OSS
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "openai/gpt-oss-safeguard-20b",
        # Moonshot AI
        "moonshotai/kimi-k2-instruct",
        "moonshotai/kimi-k2-instruct-0905",
        # Gemini 2.5 / 3
        "gemini-3-flash",
        "gemini-3-flash-preview",
        "gemini-3-pro",
        "gemini-3-pro-preview",
        "gemini-2.5-pro",
        "gemini-2.5-pro-preview-06-05",
        "gemini-2.5-pro-preview-05-06",
        "gemini-2.5-pro-preview-03-25",
        "gemini-2.5-pro-exp-03-25",
        "gemini-2.5-flash",
        "gemini-2.5-flash-preview-05-20",
        "gemini-2.5-flash-preview-04-17",
        "gemini-2.5-flash-preview-04-17-thinking",
        # Gemini 2.0
        "gemini-2.0-flash",
        "gemini-2.0-flash-001",
        "gemini-2.0-pro-exp-02-05",
        "gemini-2.0-pro-exp",
        "gemini-2.0-flash-exp",
        # Gemini 1.5
        "gemini-1.5-flash-8b-exp-0924",
        "gemini-1.5-flash-8b-exp-0827",
        "gemini-1.5-flash-8b-latest",
        "gemini-1.5-flash-8b-001",
        "gemini-1.5-flash-8b",
        "gemini-1.5-flash-002",
        "gemini-1.5-flash",
        "gemini-1.5-flash-001",
        "gemini-1.5-flash-latest",
        "gemini-1.5-pro",
        "gemini-1.5-pro-002",
        "gemini-1.5-pro-001",
        "gemini-1.5-pro-latest",
        "gemini-exp-1206",
        # Grok
        "grok-4-1-fast-reasoning",
        "grok-4-1-fast-non-reasoning",
        "grok-4",
        "grok-4-latest",
        "grok-4-0709",
        "grok-4-fast-reasoning",
        "grok-4-fast-non-reasoning",
        "grok-code-fast-1",
        "grok-2",
        "grok-2-1212",
        "grok-2-latest",
        "grok-3",
        "grok-3-beta",
        "grok-3-latest",
        "grok-3-fast",
        "grok-3-fast-beta",
        "grok-3-fast-latest",
        "grok-3-mini",
        "grok-3-mini-beta",
        "grok-3-mini-latest",
        "grok-3-mini-fast",
        "grok-3-mini-fast-beta",
        "grok-3-mini-fast-latest"
    ]

    reasoning-effort-thinking-budget-mapping {
        # No explicit extended thinking
        none {
            # Gemini:
            # - 2.5 Flash / Flash-Lite: 0 = disable thinking
            # - 2.5 Pro: 0 is out of range (128â€“32768), so your code should clamp to 128 or skip setting thinking_budget.
            gemini = 0

            # Anthropic:
            # 0 = sentinel meaning "don't enable extended thinking at all"
            # (omit the `thinking` block instead of sending budget_tokens=0).
            anthropic = 0
        }

        # Quick replies, simple Q&A, light code edits, low cost/latency
        minimal {
            gemini = 256          # above Pro's min of 128
            anthropic = 1024      # Anthropic min is 1024
        }

        # Normal app usage, small multi-step reasoning, short RAG answers
        low {
            gemini = 1024
            anthropic = 2048
        }

        # Heavier reasoning, multi-step analysis, non-trivial debugging, multi-page doc Q&A
        medium {
            gemini = 4096
            anthropic = 4096
        }

        # Hard problems: complex codebases, intricate math, multi-doc reasoning
        high {
            gemini = 8192
            anthropic = 8192
        }
    }
}